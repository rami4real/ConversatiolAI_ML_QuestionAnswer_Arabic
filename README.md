# ğŸŒŸ Chatbot en Arabe pour le Machine Learning ğŸŒŸ

---

## ğŸ“‹ Ã‰tapes Principales du Projet

### 1ï¸âƒ£ Scraping des DonnÃ©es ğŸ”
- **But :** Collecter des questions-rÃ©ponses (Q/A) pertinentes pour le machine learning en anglais.
- **Sources utilisÃ©es :**
  - [`Turing Machine Learning Questions`](https://www.turing.com/interview-questions/machine-learning)
  - [`MyGreatLearning Blog`](https://www.mygreatlearning.com/blog/machine-learning-interview-questions/)
- **Outils :** Utilisation de `Beautiful Soup` (Python) pour le scraping.

---

### 2ï¸âƒ£ Nettoyage de la Base de DonnÃ©es ğŸ§¹
- Suppression des caractÃ¨res spÃ©ciaux, des espaces inutiles et standardisation du format des donnÃ©es.
- Validation manuelle pour garantir la pertinence des donnÃ©es collectÃ©es.

---

### 3ï¸âƒ£ Traduction Anglais â†’ Arabe ğŸ”„
- **Outils utilisÃ©s :** Trois modÃ¨les de traduction de Hugging Face :
  - [`Helsinki-NLP/opus-mt-en-ar`](https://huggingface.co/Helsinki-NLP/opus-mt-en-ar)
  - [`marefa-nlp/marefa-mt-en-ar`](https://huggingface.co/marefa-nlp/marefa-mt-en-ar)
  - [`t5-v1_1-base`](https://huggingface.co/t5-v1_1-base)
- **RÃ©sultat :** Le modÃ¨le [`marefa-nlp/marefa-mt-en-ar`](https://huggingface.co/marefa-nlp/marefa-mt-en-ar) a produit les meilleures traductions en termes de qualitÃ© et de pertinence.

![marefa-nlp/marefa-mt-en-ar](Media/marefa1.jpg)

---

### 4ï¸âƒ£ Nettoyage et Formatage des Textes en Arabe âœ¨
- **Outils :** API Gemini (via prompts avancÃ©s) pour :
  - Reformuler et corriger les textes.
  - GÃ©nÃ©rer des donnÃ©es dans le format SQuAD (Q/A structurÃ©), adaptÃ© pour l'entraÃ®nement des modÃ¨les.
- **Approche :** Multi-shot pour garantir des exemples variÃ©s et cohÃ©rents.

![marefa-nlp/marefa-mt-en-ar](Media/gemini.jpg)

---

### 5ï¸âƒ£ Fine-tuning des ModÃ¨les LLM ğŸ”§
- **ModÃ¨les testÃ©s :**
  - **Finetuned Google AI Studio** (le meilleur parmi les trois modÃ¨les testÃ©s)
  - **AraBERT**
  - **T5-Small**
- **RÃ©sultat :** Bien que Finetuned Google AI Studio ait surpassÃ© les autres modÃ¨les en termes de performances, aucun des trois modÃ¨les n'a produit des rÃ©sultats satisfaisants pour la tÃ¢che spÃ©cifique.

![Performance Comparison GIF](Media/ai_studio.gif)

---

### 6ï¸âƒ£ Utilisation de Ollama et Fine-tuning ğŸš€
- **Plateforme utilisÃ©e :** Ollama
- **ModÃ¨les testÃ©s :**
  - `Mistral 7B`
  - `Llama 3.2`
- **Ã‰tapes :**
  - TÃ©lÃ©chargement et fine-tuning des modÃ¨les avec des fichiers adaptÃ©s (`modelfiles`).
- **Comparaison :** Le modÃ¨le **Mistral 7B** a dÃ©montrÃ© des performances supÃ©rieures en termes de scores WSSA et de retours qualitatifs.

![marefa-nlp/marefa-mt-en-ar](Media/mistral.png)

---

### 7ï¸âƒ£ Interface Utilisateur ğŸ’»
- CrÃ©ation d'une interface utilisateur avec **Ollama Open UI** pour interagir avec le chatbot.
- Investigation des modÃ¨les directement via l'interface pour valider leurs rÃ©ponses et effectuer des comparaisons.

![marefa-nlp/marefa-mt-en-ar](Media/interface.png)

---
## ğŸ› ï¸ Lancer les ModÃ¨les Mistral 7B et Llama 3.2 avec Ollama et Docker

### 1. Installation d'Ollama ğŸ“¥
Avant de commencer, installez Ollama sur votre machine en suivant ces Ã©tapes :

- Rendez-vous sur le site officiel d'Ollama : [https://ollama.ai](https://ollama.ai).
- TÃ©lÃ©chargez la version d'Ollama correspondant Ã  votre systÃ¨me d'exploitation (Windows, macOS ou Linux).
- Installez l'outil en suivant les instructions spÃ©cifiques Ã  votre plateforme.

---

### 2. TÃ©lÃ©charger les ModÃ¨les â¬‡ï¸
Une fois Ollama installÃ©, utilisez les commandes suivantes pour tÃ©lÃ©charger les modÃ¨les nÃ©cessaires :

#### TÃ©lÃ©charger le modÃ¨le **Mistral 7B** :
```bash
ollama pull mistral7b 
```

#### TÃ©lÃ©charger le modÃ¨le Llama 3.2 :
```bash
ollama pull llama3.2
```
---

### 3. CrÃ©er et ExÃ©cuter les ModÃ¨les âš™ï¸
Pour fine-tuner ou personnaliser les modÃ¨les avec vos propres donnÃ©es, utilisez la commande suivante :
```bash
ollama create -f <path-to-modelfile> <nom-du-modele>
```

- Remplacez <path-to-modelfile> par le chemin vers le fichier contenant vos donnÃ©es.
- Remplacez <nom-du-modele> par le nom que vous souhaitez attribuer au modÃ¨le.

#### Exemple :
```bash
ollama create -f ./data/mistral_Modelfile mistral7b-custom
```
---

### 4. Lancer les ModÃ¨les avec Docker et Open Web UI ğŸ³
Si vous souhaitez interagir avec les modÃ¨les via une interface graphique conviviale, utilisez Open Web UI avec Docker.

#### Ã‰tape 1 : Lancer le Conteneur Docker
```bash
docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway \
-v open-webui:/app/backend/data --name open-webui --restart always \
ghcr.io/open-webui/open-webui:main
```

#### Ã‰tape 2 : VÃ©rifier le Conteneur
```bash
docker ps
```
#### Ã‰tape 3 : AccÃ©der Ã  l'Interface
Ouvrez votre navigateur web et rendez-vous Ã  l'adresse suivante :

http://localhost:3000

![MON GIF](Media/Generetive_AI_Mlaa.gif)

---
## ğŸ“Š Ã‰valuation des ModÃ¨les LLaMA et Mistral7B

Ce projet Ã©value les performances des modÃ¨les **LLaMA** et **Mistral7B** en utilisant diffÃ©rentes mÃ©triques pour comparer leurs rÃ©ponses gÃ©nÃ©rÃ©es dans un contexte donnÃ©, en particulier pour des textes en langue arabe. Nous avons commencÃ© par des mÃ©triques classiques telles que **BLEU** et **ROUGE-L**, mais avons adoptÃ© une nouvelle mÃ©trique **WSAA** (Weighted Semantic Similarity with Arabic-specific Adjustments) pour une Ã©valuation plus prÃ©cise.

### 1. RÃ©sultats **BLEU** et **ROUGE-L** ğŸ“ˆ

#### Table des rÃ©sultats

| **Question** | **ModÃ¨le**   | **BLEU** | **ROUGE-L** |
|--------------|--------------|----------|-------------|
| **1**        | LLaMA        | 0.0413   | 0.3000      |
|              | Mistral7B    | 0.0820   | 0.6667      |
| **2**        | LLaMA        | 0.1083   | 0.0000      |
|              | Mistral7B    | 0.0835   | 0.3478      |
| **3**        | LLaMA        | 0.0390   | 0.0000      |
|              | Mistral7B    | 0.0159   | 0.0000      |

#### Observations ğŸ”

Les rÃ©sultats des mÃ©triques **BLEU** et **ROUGE-L** montrent que ni **LLaMA** ni **Mistral7B** n'ont atteint des performances satisfaisantes, particuliÃ¨rement dans la question 3 oÃ¹ les scores sont trÃ¨s faibles. Ces mÃ©triques classiques ne semblent pas adaptÃ©es pour cette tÃ¢che spÃ©cifique en arabe.

---

### 2. Adopting the **WSAA** Metric ğŸ“

Pour une Ã©valuation plus pertinente, nous avons choisi d'adopter la **mÃ©trique WSAA** (Weighted Semantic Similarity with Arabic-specific Adjustments). Cette mÃ©trique prend en compte plusieurs aspects importants :

- **CohÃ©rence SÃ©mantique** : Mesure de la similaritÃ© sÃ©mantique entre la rÃ©ponse gÃ©nÃ©rÃ©e et la rÃ©fÃ©rence.
- **Couverture de Domaine** : Mesure dans quelle mesure les termes spÃ©cifiques au domaine sont couverts dans les rÃ©ponses gÃ©nÃ©rÃ©es.
- **Composants supplÃ©mentaires** : BLEU et ROUGE sont Ã©galement pris en compte dans cette mÃ©trique ajustÃ©e pour l'arabe.

---

### 3. RÃ©sultats **WSAA** ğŸ“Š

#### Table des rÃ©sultats

| **Question** | **ModÃ¨le**   | **Score Final** | **CohÃ©rence SÃ©mantique** | **Couverture de Domaine** |
|--------------|--------------|-----------------|--------------------------|---------------------------|
| **1**        | LLaMA        | 0.3163          | 0.8001                   | 0.0000                    |
|              | Mistral7B    | 0.3662          | 0.8205                   | 0.0000                    |
| **2**        | LLaMA        | 0.3225          | 0.8749                   | 0.0000                    |
|              | Mistral7B    | 0.3461          | 0.8538                   | 0.0000                    |
| **3**        | LLaMA        | 0.3425          | 0.7832                   | 0.2500                    |
|              | Mistral7B    | 0.3900          | 0.9289                   | 0.2500                    |

---

### 4. Conclusion : Le Meilleur ModÃ¨le ğŸ†

En conclusion, bien que **LLaMA** ait montrÃ© des performances initiales acceptables selon certaines mÃ©triques, **Mistral7B** s'avÃ¨re Ãªtre le modÃ¨le le plus performant sur la base de notre mÃ©trique **WSAA**. Cela en fait le choix optimal pour gÃ©nÃ©rer des rÃ©ponses cohÃ©rentes et pertinentes, en particulier dans un contexte en arabe.

Nous recommandons donc **Mistral7B** comme modÃ¨le principal pour les tÃ¢ches de gÃ©nÃ©ration de texte dans ce domaine.

---

## ğŸš€ RÃ©sultats et Prochaines Ã‰tapes
- **Meilleur modÃ¨le :** `Mistral 7B`
- **Prochaines Ã©tapes :**
  - AmÃ©liorer la robustesse du chatbot sur d'autres dialectes arabes ğŸŒ
  -  ImplÃ©menter un systÃ¨me de feedback utilisateur pour amÃ©liorer les rÃ©ponses ğŸ“
  -  DÃ©velopper une API RESTful pour faciliter l'intÃ©gration ğŸ”—

  

---

## ğŸ‘¥ Contributions

Ce projet a Ã©tÃ© dÃ©veloppÃ© en collaboration par :

- **Mohamed Habib Kammoun** ğŸ‘¨â€ğŸ’»
- **Ahmed Rami Belguith** ğŸ‘¨â€ğŸ’»
- **Dhia Elhak Toukebri** ğŸ‘¨â€ğŸ’»

<a href="https://github.com/habibkammoun/GenrativeIA_ML_questions_arabic/graphs/contributors">
    <img src="https://contrib.rocks/image?repo=habibkammoun/GenrativeIA_ML_questions_arabic" />
</a>
